# -*- coding: utf-8 -*-
"""Proyek Akhir_Sistem Rekomendasi_Safiira Rahmah Linisa

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HKlIrhWlhxICWwMeEUKxAS1xrQk1WYFj

# Sistem Rekomendasi Buku

###Proyek Akhir Machine Learning Terapan

* Nama : Safiira Rahmah Linisa
* SIB ID : M248Y0537
* SIB Group : M02

Dowload data dari kaggle kemudian unzip file yang sudah didowload.
"""

! chmod 600 /content/kaggle.json

! KAGGLE_CONFIG_DIR=/content/ kaggle datasets download -d justinnguyen0x0x/best-books-of-the-21st-century-dataset

"""##Data Understanding

Import terlebih dahulu library yang dibutuhkan
"""

# Import library
import pandas as pd
import numpy as np 
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

import zipfile
zip_file = zipfile.ZipFile('/content/best-books-of-the-21st-century-dataset.zip')
zip_file.extractall('/tmp/')
zip_file.close()

"""###Data Loading

Membaca datset menggunakan fungsi pandas, kemudian melihat isi dataset dengan memanggil variabel yang berisi dataset tersebut.
"""

book = pd.read_csv('/tmp/Best_Book_21st.csv')
book

"""##**Data Preprocessing**

Melihat informasi pada data
"""

book.info()

"""Melihat informasi teratas"""

book.head()

book.describe()

"""##**Data Preparation**

Memeriksa Missing Value Pada dataset
"""

book.isnull().sum()

"""Dari hasil diatas dapat dilihat bahwa pada dataset terdapat banyak variabel yang memiliki missing value.

Selanjutnya menghapus variabel yang tidak diperlukan serta variabel mengandung banyak missing value dengan fungsi drop.
"""

book.drop(['series', 'book_link', 'date_published', 'publisher', 'num_of_page', 'lang', 'rating_count', 'award'], axis = 1, inplace = True)

book

len(book)

book.isnull().sum()

"""Menghapus missing value pada data"""

book_clean = book.dropna()
book_clean

book_clean.isnull().sum()

len(book_clean)

# Mengurutkan buku berdasarkan id kemudian memasukkannya ke dalam variabel fix_book
fix_book = book_clean.sort_values('id', ascending=True)
fix_book

# Mengecek berapa jumlah fix_book
len(fix_book.id.unique())

# Membuat variabel preparation yang berisi dataframe fix_book kemudian mengurutkan berdasarkan id
preparation = fix_book
preparation.sort_values('id')

"""**Menghapus Data Duplikat**"""

# Membuang data duplikat pada variabel preparation
preparation = preparation.drop_duplicates('title')
preparation

"""Mengkonversi data series menjadi list menggunakan fungsi tolist() dari library numpy."""

# Mengonversi data series ‘id’ menjadi dalam bentuk list
book_id = preparation['id'].tolist()
 
# Mengonversi data series ‘title’ menjadi dalam bentuk list
book_title = preparation['title'].tolist()
 
# Mengonversi data series ‘author’ menjadi dalam bentuk list
book_author = preparation['author'].tolist()

# Mengonversi data series ‘genre’ menjadi dalam bentuk list
book_genre = preparation['genre'].tolist()
 
 # Mengonversi data series ‘review_count’ menjadi dalam bentuk list
book_review_count = preparation['review_count'].tolist()
 
 # Mengonversi data series ‘rate’ menjadi dalam bentuk list
book_rate = preparation['rate'].tolist()
 
 
print(len(book_id))
print(len(book_title))
print(len(book_author))
print(len(book_genre))
print(len(book_review_count))
print(len(book_rate))

# Membuat dictionary untuk data ‘id’, ‘title’, ‘author’, ‘genre’, ‘review’ dan ‘rate’.
book_new = pd.DataFrame({
    'id': book_id,
    'title': book_title,
    'author': book_author,
    'genre': book_genre,
    'review_count': book_review_count,
    'rate': book_rate
})
book_new

"""##Model Development dengan content based filtering"""

data = book_new
data.sample(5)

"""TF-IDF Vectorizer"""

from sklearn.feature_extraction.text import TfidfVectorizer
 
# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()
 
# Melakukan perhitungan idf pada data genre
tf.fit(data['genre']) 
 
# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names()

"""Melakukan fit dan transformasi ke dalam bentuk matriks"""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['genre']) 
 
# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan genre buku
# Baris diisi dengan judul buku
 
pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=data.title
).sample(22, axis=1).sample(10, axis=0)

"""**Cosine Similarity**"""

from sklearn.metrics.pairwise import cosine_similarity
 
# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa tilte
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['title'], columns=data['title'])
print('Shape:', cosine_sim_df.shape)
 
# Melihat similarity matrix pada setiap judul buku
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

def book_recommendations(title, similarity_data=cosine_sim_df, items=data[['title', 'genre']], k=5):
    """
    Rekomendasi buku berdasarkan kemiripan dataframe
 
    Parameter:
    ---
    title : tipe data string (str)
                judul buku (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan judul sebagai 
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---
 
 
    Pada index ini, kita mengambil k dengan nilai similarity terbesar 
    pada index matrix yang diberikan (i).
    """
 
 
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,title].to_numpy().argpartition(
        range(-1, -k, -1))
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    # Drop title agar titleo yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(title, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

"""sejumlah rekomendasi buku pada pengguna yang diatur dalam parameter k."""

data[data.title.eq('The Great Good Thing (The Sylvie Cycle, #1)')]

# Mendapatkan rekomendasi buku yang mirip dengan 'blaze'
book_recommendations('The Great Good Thing (The Sylvie Cycle, #1)')